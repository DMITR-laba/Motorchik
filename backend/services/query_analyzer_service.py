"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Ö —Ç–∏–ø–∞ (—Ç–æ—á–Ω—ã–π/—Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–π)
—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""
import re
import json
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)


class QueryType(Enum):
    """–¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞"""
    VAGUE = "vague"  # –†–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–π
    SPECIFIC = "specific"  # –¢–æ—á–Ω—ã–π
    MIXED = "mixed"  # –°–º–µ—à–∞–Ω–Ω—ã–π


@dataclass
class QueryAnalysis:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    query_type: QueryType
    vague_components: List[str]
    specific_components: List[str]
    needs_clarification: bool
    clarification_questions: List[str]
    confidence: float


@dataclass
class GeneratedParameters:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
    vague_component: str
    sql_conditions: Dict[str, Any]
    explanation: str
    confidence: float


class QueryAnalyzerService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM"""
    
    def __init__(self, ai_service=None, langchain_service=None, model: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
        
        Args:
            ai_service: –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å AI (AIService)
            langchain_service: –°–µ—Ä–≤–∏—Å LangChain (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è codellama:34b)
        """
        self.ai_service = ai_service
        self.langchain_service = langchain_service
        self.model = model or "codellama:34b"  # –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.clarification_context = {}
        
        if model:
            logger.info(f"üîß QueryAnalyzer –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å: {model}")
        else:
            logger.info(f"üîß QueryAnalyzer –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {self.model}")
    
    async def analyze_query(self, user_query: str) -> QueryAnalysis:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é LLM –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        
        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            QueryAnalysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        # logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {user_query}")  # –û–¢–ö–õ–Æ–ß–ï–ù–û
        
        analysis_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–ø—Ä–æ—Å —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–µ (vague) –∏/–∏–ª–∏ —Ç–æ—á–Ω—ã–µ (specific) –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã.

–†–ê–°–ü–õ–´–í–ß–ê–¢–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´: —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è, –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
- "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π", "–±—ã—Å—Ç—Ä—ã–π", "–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π", "—Å—Ç–∏–ª—å–Ω—ã–π", "—ç–ª–µ–≥–∞–Ω—Ç–Ω—ã–π"
- "—á—Ç–æ-—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ", "–ø–æ—Ö–æ–∂–∏–π –Ω–∞...", "–Ω–µ–ø–ª–æ—Ö–æ–π"
- "–Ω–µ —Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ–π", "–¥–æ–≤–æ–ª—å–Ω–æ –º–æ—â–Ω—ã–π", "–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç–æ—Ä–Ω—ã–π"
- "–∫—Ä–∞—Å–∏–≤—ã–π", "–Ω–∞–¥–µ–∂–Ω—ã–π", "—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π"

–¢–û–ß–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´: –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, —á–∏—Å–ª–∞, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- "–∫—Ä–∞—Å–Ω—ã–π", "BMW", "2020 –≥–æ–¥–∞", "—Ç–æ–π–æ—Ç–∞", "toyota", "Toyota"
- "–º–æ—â–Ω–æ—Å—Ç—å 150 –ª.—Å.", "—Ü–µ–Ω–∞ –¥–æ 50000", "–¥–æ 5 –º–ª–Ω"
- "–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä–æ–±–∫–∞", "–¥–∏–∑–µ–ª—å–Ω—ã–π –¥–≤–∏–≥–∞—Ç–µ–ª—å", "–∞–≤—Ç–æ–º–∞—Ç", "–º–µ—Ö–∞–Ω–∏–∫–∞"
- "—Å–µ–¥–∞–Ω", "–∫—Ä–æ—Å—Å–æ–≤–µ—Ä", "–±–µ–Ω–∑–∏–Ω", "–¥–∏–∑–µ–ª—å"
- "–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"
- "–ø—Ä–æ–±–µ–≥ –¥–æ 100000", "–ø—Ä–æ–±–µ–≥–æ–º –¥–æ 10000 –∫–º", "–Ω–µ —Å—Ç–∞—Ä—à–µ 2013 –≥–æ–¥–∞", "—Å –ø—Ä–æ–±–µ–≥–æ–º"
- "–ø–æ–¥–±–µ—Ä–∏", "–Ω–∞–π–¥–∏", "–ø–æ–∫–∞–∂–∏" - —ç—Ç–æ –∫–æ–º–∞–Ω–¥—ã, –ù–ï —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã!

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: "{user_query}"

–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ markdown):
{{
    "query_type": "vague|specific|mixed",
    "vague_components": ["—Å–ø–∏—Å–æ–∫ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã—Ö —á–∞—Å—Ç–µ–π –∑–∞–ø—Ä–æ—Å–∞"],
    "specific_components": ["—Å–ø–∏—Å–æ–∫ —Ç–æ—á–Ω—ã—Ö —á–∞—Å—Ç–µ–π –∑–∞–ø—Ä–æ—Å–∞"], 
    "needs_clarification": true/false,
    "clarification_questions": ["–≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"],
    "confidence": 0.85
}}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê: 
1. –¢–ò–ü –ó–ê–ü–†–û–°–ê:
   - –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–º–∞—Ä–∫–∞, –º–æ–¥–µ–ª—å, –≥–æ–¥, —Ü–µ–Ω–∞, –ø—Ä–æ–±–µ–≥, –ö–ü–ü, —Ç–æ–ø–ª–∏–≤–æ, –∫—É–∑–æ–≤) - query_type = "specific"
   - –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –ë–ï–ó –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ - query_type = "vague"
   - –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏ —Ç–æ, –∏ –¥—Ä—É–≥–æ–µ - query_type = "mixed"

2. –£–¢–û–ß–ù–ï–ù–ò–ï (needs_clarification):
   - needs_clarification = true –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ü–û–õ–ù–û–°–¢–¨–Æ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–π –ë–ï–ó –õ–Æ–ë–´–• –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
   - –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏—è: "—á—Ç–æ-—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ", "—á—Ç–æ-—Ç–æ —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–µ", "–ø–æ–¥–±–µ—Ä–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å"
   - –ï—Å–ª–∏ –µ—Å—Ç—å –•–û–¢–Ø –ë–´ –û–î–ò–ù —Ç–æ—á–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (–º–∞—Ä–∫–∞, –º–æ–¥–µ–ª—å, –≥–æ–¥, –ø—Ä–æ–±–µ–≥, —Ü–µ–Ω–∞, –ö–ü–ü, —Ç–æ–ø–ª–∏–≤–æ, –∫—É–∑–æ–≤, –≥–æ—Ä–æ–¥) - needs_clarification = false
   - –ü—Ä–∏–º–µ—Ä—ã –ù–ï —Ç—Ä–µ–±—É—é—â–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏—è: "toyota —Å –ø—Ä–æ–±–µ–≥–æ–º –¥–æ 10000", "BMW 2020 –≥–æ–¥–∞", "–∫—Ä–∞—Å–Ω—ã–π —Å–µ–¥–∞–Ω", "–ø–æ–¥–±–µ—Ä–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏ toyota —Å –ø—Ä–æ–±–µ–≥–æ–º –¥–æ 10000 –∫–º"

3. –†–ê–°–ü–õ–´–í–ß–ê–¢–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´:
   - –ù–ï –≤–∫–ª—é—á–∞–π –≤ vague_components –∫–æ–º–∞–Ω–¥—ã: "–ø–æ–¥–±–µ—Ä–∏", "–Ω–∞–π–¥–∏", "–ø–æ–∫–∞–∂–∏", "–∏—â—É" - —ç—Ç–æ –∫–æ–º–∞–Ω–¥—ã, –Ω–µ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è!
   - –ù–ï –≤–∫–ª—é—á–∞–π –≤ vague_components –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: "toyota", "–ø—Ä–æ–±–µ–≥", "10000" - —ç—Ç–æ —Ç–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã!

4. –¢–û–ß–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´:
   - –í–∫–ª—é—á–∞–π –º–∞—Ä–∫–∏: "toyota", "bmw", "mercedes" –∏ —Ç.–¥.
   - –í–∫–ª—é—á–∞–π –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: "–ø—Ä–æ–±–µ–≥ –¥–æ 10000", "–Ω–µ —Å—Ç–∞—Ä—à–µ 2013", "—Ü–µ–Ω–∞ –¥–æ 5 –º–ª–Ω"
   - –í–∫–ª—é—á–∞–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: "–∞–≤—Ç–æ–º–∞—Ç", "–º–µ—Ö–∞–Ω–∏–∫–∞", "–±–µ–Ω–∑–∏–Ω", "—Å–µ–¥–∞–Ω", "–∫—Ä–∞—Å–Ω—ã–π"
"""
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º LangChain –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if self.langchain_service:
                response = await self._analyze_with_langchain(analysis_prompt)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π API —á–µ—Ä–µ–∑ ai_service
                response = await self._analyze_with_direct_api(analysis_prompt)
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            result = self._parse_json_response(response)
            
            # –ï—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
            if result is None:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –∞–Ω–∞–ª–∏–∑")
                return self._fallback_analysis(user_query)
            
            # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            analysis = QueryAnalysis(
                query_type=QueryType(result.get("query_type", "mixed")),
                vague_components=result.get("vague_components", []),
                specific_components=result.get("specific_components", []),
                needs_clarification=result.get("needs_clarification", False),
                clarification_questions=result.get("clarification_questions", []),
                confidence=float(result.get("confidence", 0.5))
            )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –Ω–µ —Ç—Ä–µ–±—É–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏—è
            if analysis.specific_components and len(analysis.specific_components) > 0:
                analysis.needs_clarification = False
                # logger.info(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã ({len(analysis.specific_components)}), —É—Ç–æ—á–Ω–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")  # –û–¢–ö–õ–Æ–ß–ï–ù–û
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            # Fallback –∞–Ω–∞–ª–∏–∑
            return self._fallback_analysis(user_query)
    
    async def _analyze_with_langchain(self, prompt: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LangChain"""
        try:
            from langchain_core.output_parsers import StrOutputParser
            from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
            
            system_template = "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
            user_template = "{prompt}"
            
            prompt_template = ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template(system_template),
                HumanMessagePromptTemplate.from_template(user_template)
            ])
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            llm = self.langchain_service.get_llm(self.model, None)
            chain = prompt_template | llm | StrOutputParser()
            
            result = await chain.ainvoke({"prompt": prompt})
            return result
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ LangChain: {e}")
            # Fallback –Ω–∞ –ø—Ä—è–º–æ–π API
            return await self._analyze_with_direct_api(prompt)
    
    async def _analyze_with_direct_api(self, prompt: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π API"""
        if not self.ai_service:
            raise Exception("AI service –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Ollama –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        from services.ollama_utils import find_working_ollama_url
        working_url = await find_working_ollama_url(timeout=2.0)
        if not working_url:
            raise Exception("Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ (—É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "ollama:" –µ—Å–ª–∏ –µ—Å—Ç—å)
        model_name = self.model.replace("ollama:", "") if self.model.startswith("ollama:") else self.model
        
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{working_url}/api/generate",
                json={
                    "model": model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "num_predict": 2048
                    }
                },
                timeout=60
            )
            response.raise_for_status()
            data = response.json()
            return data.get("response", "")
    
    def _parse_json_response(self, text: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ–∏—Å–∫ JSON
            cleaned_text = text.strip()
            
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ markdown –±–ª–æ–∫–∏ –∫–æ–¥–∞
            cleaned_text = re.sub(r'```json\s*', '', cleaned_text)
            cleaned_text = re.sub(r'```\s*', '', cleaned_text)
            
            # –ò—â–µ–º JSON –æ–±—ä–µ–∫—Ç
            json_match = re.search(r'\{.*\}', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º needs_clarification
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã - –Ω–µ —Ç—Ä–µ–±—É–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏—è
                if result.get("specific_components") and len(result.get("specific_components", [])) > 0:
                    result["needs_clarification"] = False
                    # logger.info(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, —É—Ç–æ—á–Ω–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")  # –û–¢–ö–õ–Æ–ß–ï–ù–û
                
                return result
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–∞–∫ JSON
                result = json.loads(cleaned_text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º needs_clarification
                if result.get("specific_components") and len(result.get("specific_components", [])) > 0:
                    result["needs_clarification"] = False
                
                return result
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}\n–¢–µ–∫—Å—Ç: {text[:200]}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –∞–Ω–∞–ª–∏–∑
            return None  # –í–µ—Ä–Ω–µ–º None, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback
    
    def _fallback_analysis(self, user_query: str) -> QueryAnalysis:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ LLM"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è fallback
        vague_keywords = ["—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π", "–±—ã—Å—Ç—Ä—ã–π", "–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π", "—Å—Ç–∏–ª—å–Ω—ã–π", "–∫—Ä–∞—Å–∏–≤—ã–π", 
                         "–Ω–∞–¥–µ–∂–Ω—ã–π", "—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π", "—á—Ç–æ-—Ç–æ", "–ø–æ—Ö–æ–∂–∏–π", "–Ω–µ–ø–ª–æ—Ö–æ–π"]
        specific_keywords = ["bmw", "—Ç–æ–π–æ—Ç–∞", "toyota", "mercedes", "–∫—Ä–∞—Å–Ω—ã–π", "—Å–∏–Ω–∏–π", "–∞–≤—Ç–æ–º–∞—Ç", 
                           "–º–µ—Ö–∞–Ω–∏–∫–∞", "–±–µ–Ω–∑–∏–Ω", "–¥–∏–∑–µ–ª—å", "—Å–µ–¥–∞–Ω", "–∫—Ä–æ—Å—Å–æ–≤–µ—Ä", "–ø—Ä–æ–±–µ–≥", "–ø—Ä–æ–±–µ–≥–æ–º",
                           "–¥–æ", "–Ω–µ —Å—Ç–∞—Ä—à–µ", "–≥–æ–¥", "–≥–æ–¥–∞", "–º–æ—â–Ω–æ—Å—Ç—å", "—Ü–µ–Ω–∞", "–º–æ—Å–∫–≤–∞", "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥"]
        
        query_lower = user_query.lower()
        has_vague = any(kw in query_lower for kw in vague_keywords)
        has_specific = any(kw in query_lower for kw in specific_keywords)
        
        if has_vague and has_specific:
            query_type = QueryType.MIXED
        elif has_vague:
            query_type = QueryType.VAGUE
        else:
            query_type = QueryType.SPECIFIC
        
        # –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–π –ë–ï–ó –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        needs_clarification = query_type == QueryType.VAGUE and not has_specific
        
        return QueryAnalysis(
            query_type=query_type,
            vague_components=[kw for kw in vague_keywords if kw in query_lower] if has_vague else [],
            specific_components=[kw for kw in specific_keywords if kw in query_lower] if has_specific else [],
            needs_clarification=needs_clarification,
            clarification_questions=["–£—Ç–æ—á–Ω–∏—Ç–µ, –∫–∞–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –≤–∞–º –≤–∞–∂–Ω—ã?"] if needs_clarification else [],
            confidence=0.5
        )
    
    async def generate_parameters(self, vague_components: List[str], 
                                 context: Dict = None) -> List[GeneratedParameters]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        
        Args:
            vague_components: –°–ø–∏—Å–æ–∫ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–æ—á–Ω–µ–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            List[GeneratedParameters]: –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        """
        if not vague_components:
            return []
        
        # logger.info(f"üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {len(vague_components)} —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")  # –û–¢–ö–õ–Æ–ß–ï–ù–û
        
        generated_params = []
        
        for component in vague_components:
            params = await self._generate_for_component(component, context)
            generated_params.append(params)
            # logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è '{component}': {params.sql_conditions} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {params.confidence})")  # –û–¢–ö–õ–Æ–ß–ï–ù–û
        
        return generated_params
    
    async def _generate_for_component(self, vague_component: str, context: Dict) -> GeneratedParameters:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        
        generation_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–∞.

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
2. –û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ–¥—Ö–æ–¥—è—Ç –ø–æ–¥ —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ
3. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –≤–∏–¥–µ —É—Å–ª–æ–≤–∏–π –¥–ª—è SQL WHERE
4. –û–±—ä—è—Å–Ω–∏ –ª–æ–≥–∏–∫—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è

–ü–†–ò–ú–ï–†–´ –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–Ø:
- "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π" -> –≤—ã—Å–æ–∫–∞—è –º–æ—â–Ω–æ—Å—Ç—å (power > 200), –±—ã—Å—Ç—Ä—ã–π —Ä–∞–∑–≥–æ–Ω, —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Ç–∏–ø –∫—É–∑–æ–≤–∞ (–∫—É–ø–µ, —Å–µ–¥–∞–Ω)
- "–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π" -> –ø—Ä–æ—Å—Ç–æ—Ä–Ω—ã–π —Å–∞–ª–æ–Ω, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä–æ–±–∫–∞ (gear_box_type LIKE '%–∞–≤—Ç–æ–º–∞—Ç%' OR gear_box_type LIKE '%automatic%'), –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä
- "—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π" -> –Ω–∏–∑–∫–∏–π —Ä–∞—Å—Ö–æ–¥, –¥–æ—Å—Ç—É–ø–Ω–∞—è —Ü–µ–Ω–∞ (price < 2000000), –Ω–µ–±–æ–ª—å—à–æ–π –æ–±—ä–µ–º –¥–≤–∏–≥–∞—Ç–µ–ª—è (engine_vol < 2000)
- "—Å—Ç–∏–ª—å–Ω—ã–π" -> —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –≥–æ–¥ (manufacture_year >= 2020), –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π —Ü–≤–µ—Ç
- "–Ω–∞–¥–µ–∂–Ω—ã–π" -> –Ω–µ —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–π (manufacture_year >= 2015), –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å

–ü—Ä–µ–æ–±—Ä–∞–∑—É–π —ç—Ç–æ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ SQL-—É—Å–ª–æ–≤–∏—è: "{vague_component}"

–ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–æ—á–Ω–µ–Ω–∏–π: {json.dumps(context, ensure_ascii=False) if context else "–Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω"}

–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ markdown):
{{
    "vague_component": "{vague_component}",
    "sql_conditions": {{
        "field1": "value1",
        "field2": {{"min": 100, "max": 200}},
        "field3": ["option1", "option2"]
    }},
    "explanation": "–ª–æ–≥–∏–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
    "confidence": 0.9
}}

–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π –ë–î:
- mark, model, price, manufacture_year, city, body_type, fuel_type, gear_box_type, driving_gear_type
- mileage (—Ç–æ–ª—å–∫–æ –¥–ª—è used_cars), power, engine_vol, color
- –î–ª—è price –∏—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä—É–±–ª—è—Ö
- –î–ª—è manufacture_year –∏—Å–ø–æ–ª—å–∑—É–π —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ (–≥–æ–¥)
- –î–ª—è mileage –∏—Å–ø–æ–ª—å–∑—É–π —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ (–∫–∏–ª–æ–º–µ—Ç—Ä—ã)
- –î–ª—è power –∏—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–ª–æ—à–∞–¥–∏–Ω—ã–µ —Å–∏–ª—ã)
- –î–ª—è engine_vol –∏—Å–ø–æ–ª—å–∑—É–π —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ (–∫—É–±–∏—á–µ—Å–∫–∏–µ —Å–∞–Ω—Ç–∏–º–µ—Ç—Ä—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä 2000 = 2.0–ª)
"""
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º LangChain –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if self.langchain_service:
                response = await self._generate_with_langchain(generation_prompt)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π API
                response = await self._generate_with_direct_api(generation_prompt)
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            result = self._parse_json_response(response)
            
            return GeneratedParameters(
                vague_component=result.get("vague_component", vague_component),
                sql_conditions=result.get("sql_conditions", {}),
                explanation=result.get("explanation", ""),
                confidence=float(result.get("confidence", 0.5))
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è '{vague_component}': {e}")
            return self._fallback_parameters(vague_component)
    
    async def _generate_with_langchain(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ LangChain"""
        try:
            from langchain_core.output_parsers import StrOutputParser
            from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
            
            system_template = "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
            user_template = "{prompt}"
            
            prompt_template = ChatPromptTemplate.from_messages([
                SystemMessagePromptTemplate.from_template(system_template),
                HumanMessagePromptTemplate.from_template(user_template)
            ])
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            llm = self.langchain_service.get_llm(self.model, None)
            chain = prompt_template | llm | StrOutputParser()
            
            result = await chain.ainvoke({"prompt": prompt})
            return result
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ LangChain: {e}")
            # Fallback –Ω–∞ –ø—Ä—è–º–æ–π API
            return await self._generate_with_direct_api(prompt)
    
    async def _generate_with_direct_api(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π API"""
        from services.ollama_utils import find_working_ollama_url
        working_url = await find_working_ollama_url(timeout=2.0)
        if not working_url:
            raise Exception("Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏ (—É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "ollama:" –µ—Å–ª–∏ –µ—Å—Ç—å)
        model_name = self.model.replace("ollama:", "") if self.model.startswith("ollama:") else self.model
        
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{working_url}/api/generate",
                json={
                    "model": model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "num_predict": 2048
                    }
                },
                timeout=60
            )
            response.raise_for_status()
            data = response.json()
            return data.get("response", "")
    
    def _fallback_parameters(self, vague_component: str) -> GeneratedParameters:
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –ü—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è fallback
        component_lower = vague_component.lower()
        sql_conditions = {}
        
        if "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π" in component_lower or "–±—ã—Å—Ç—Ä—ã–π" in component_lower:
            sql_conditions = {"power": {"min": 200}}
        elif "–∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π" in component_lower:
            sql_conditions = {"gear_box_type": ["–∞–≤—Ç–æ–º–∞—Ç", "automatic"]}
        elif "—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π" in component_lower:
            sql_conditions = {"price": {"max": 2000000}, "engine_vol": {"max": 2000}}
        elif "—Å—Ç–∏–ª—å–Ω—ã–π" in component_lower or "–∫—Ä–∞—Å–∏–≤—ã–π" in component_lower:
            sql_conditions = {"manufacture_year": {"min": 2020}}
        
        return GeneratedParameters(
            vague_component=vague_component,
            sql_conditions=sql_conditions,
            explanation="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (fallback)",
            confidence=0.3
        )
    
    def combine_components(self, original_query: str,
                          specific_components: List[str],
                          generated_params: List[GeneratedParameters]) -> str:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–æ—á–Ω—ã–µ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        
        Args:
            original_query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            specific_components: –¢–æ—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            generated_params: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            str: –§–∏–Ω–∞–ª—å–Ω—ã–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        """
        if not generated_params:
            return original_query
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confident_params = [p for p in generated_params if p.confidence > 0.5]
        
        if not confident_params:
            return original_query
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∫ –∑–∞–ø—Ä–æ—Å—É
        additions = []
        for param in confident_params:
            conditions = param.sql_conditions
            if conditions:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —É—Å–ª–æ–≤–∏—è –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫
                conditions_text = self._conditions_to_text(conditions)
                if conditions_text:
                    additions.append(conditions_text)
        
        if additions:
            combined = f"{original_query}. {', '.join(additions)}"
            # logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {combined}")  # –û–¢–ö–õ–Æ–ß–ï–ù–û
            return combined
        
        return original_query
    
    def _conditions_to_text(self, conditions: Dict[str, Any]) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç SQL —É—Å–ª–æ–≤–∏—è –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫"""
        parts = []
        
        for field, value in conditions.items():
            if isinstance(value, dict):
                if "min" in value:
                    if field == "price":
                        parts.append(f"—Ü–µ–Ω–∞ –æ—Ç {value['min']:,} —Ä—É–±–ª–µ–π")
                    elif field == "power":
                        parts.append(f"–º–æ—â–Ω–æ—Å—Ç—å –æ—Ç {value['min']} –ª.—Å.")
                    elif field == "manufacture_year":
                        parts.append(f"–Ω–µ —Å—Ç–∞—Ä—à–µ {value['min']} –≥–æ–¥–∞")
                    elif field == "mileage":
                        parts.append(f"–ø—Ä–æ–±–µ–≥ –æ—Ç {value['min']} –∫–º")
                
                if "max" in value:
                    if field == "price":
                        parts.append(f"—Ü–µ–Ω–∞ –¥–æ {value['max']:,} —Ä—É–±–ª–µ–π")
                    elif field == "power":
                        parts.append(f"–º–æ—â–Ω–æ—Å—Ç—å –¥–æ {value['max']} –ª.—Å.")
                    elif field == "manufacture_year":
                        parts.append(f"–Ω–µ –Ω–æ–≤–µ–µ {value['max']} –≥–æ–¥–∞")
                    elif field == "mileage":
                        parts.append(f"–ø—Ä–æ–±–µ–≥ –¥–æ {value['max']} –∫–º")
                    elif field == "engine_vol":
                        parts.append(f"–æ–±—ä–µ–º –¥–≤–∏–≥–∞—Ç–µ–ª—è –¥–æ {value['max']} —Å–º¬≥")
            
            elif isinstance(value, list):
                if field == "gear_box_type":
                    if "–∞–≤—Ç–æ–º–∞—Ç" in str(value).lower() or "automatic" in str(value).lower():
                        parts.append("–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä–æ–±–∫–∞ –ø–µ—Ä–µ–¥–∞—á")
                    elif "–º–µ—Ö–∞–Ω–∏–∫–∞" in str(value).lower() or "manual" in str(value).lower():
                        parts.append("–º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∞—è –∫–æ—Ä–æ–±–∫–∞ –ø–µ—Ä–µ–¥–∞—á")
                elif field == "body_type":
                    parts.append(f"–∫—É–∑–æ–≤: {', '.join(value)}")
                elif field == "fuel_type":
                    parts.append(f"—Ç–æ–ø–ª–∏–≤–æ: {', '.join(value)}")
            
            elif isinstance(value, str):
                parts.append(f"{field}: {value}")
        
        return ", ".join(parts) if parts else ""
    
    def provide_clarification(self, clarification_data: Dict):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É—Ç–æ—á–Ω—è—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        self.clarification_context.update(clarification_data)
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–æ—á–Ω–µ–Ω–∏–π: {self.clarification_context}")
    
    def reset_context(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–æ—á–Ω–µ–Ω–∏–π"""
        self.clarification_context = {}
        logger.info("üîÑ –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–æ—á–Ω–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω")

