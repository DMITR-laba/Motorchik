"""
API –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ AI –∏–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional
import json
import os
from datetime import datetime
from models import get_db
from models.schemas import (
    AIModelSettings, TaskModelConfig, TaskModelUpdate,
    ModelConfigResponse, ModelTestRequest, ModelTestResponse,
    ModelPerformanceMetrics, BulkModelUpdateRequest, BulkModelUpdateResponse
)
from services.ai_service import AIService
from services.ai_model_orchestrator_service import AIModelOrchestratorService, TaskType
from services.rag_service import _generate_with_ai_settings
from app.api.auth import require_admin

router = APIRouter(prefix="/api/models", tags=["model-management"])


@router.get("/config", response_model=ModelConfigResponse)
async def get_model_config(
    db: Session = Depends(get_db)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π
    """
    try:
        orchestrator = AIModelOrchestratorService()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∑–∞–¥–∞—á
        task_mapping = orchestrator.config.get("task_model_mapping", {})
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
        task_model_config = {}
        for task, config in task_mapping.items():
            task_model_config[task] = TaskModelConfig(
                primary=config.get("primary", ""),
                fallback=config.get("fallback", ""),
                complexity=config.get("complexity", "light")
            )
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
        available_models = await orchestrator.get_available_models()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI
        ai_settings = _load_ai_settings()
        current_settings = AIModelSettings(
            response_model=ai_settings.get("response_model", ""),
            embedding_model=ai_settings.get("embedding_model", ""),
            api_service=ai_settings.get("api_service"),
            api_key=ai_settings.get("api_key"),
            deep_thinking_model=ai_settings.get("deep_thinking_model", ""),
            deepseek_api_key=ai_settings.get("deepseek_api_key", "")
        )
        
        return ModelConfigResponse(
            task_model_mapping=task_model_config,
            available_models=available_models,
            current_ai_settings=current_settings
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {str(e)}")


@router.put("/config/task", response_model=Dict[str, Any])
async def update_task_model(
    update: TaskModelUpdate,
    db: Session = Depends(get_db),
    _: object = Depends(require_admin)
):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_paths = [
            "backend/ai_model_config.json",
            "ai_model_config.json",
            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "ai_model_config.json")
        ]
        
        config_path = None
        for path in config_paths:
            if os.path.exists(path):
                config_path = path
                break
        
        if not config_path:
            config_path = config_paths[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –ø—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)
        else:
            config = {"task_model_mapping": {}}
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∑–∞–¥–∞—á–∏
        if "task_model_mapping" not in config:
            config["task_model_mapping"] = {}
        
        if update.task_type not in config["task_model_mapping"]:
            config["task_model_mapping"][update.task_type] = {
                "primary": "",
                "fallback": "",
                "complexity": "light"
            }
        
        task_config = config["task_model_mapping"][update.task_type]
        
        if update.primary is not None:
            task_config["primary"] = update.primary
        if update.fallback is not None:
            task_config["fallback"] = update.fallback
        if update.complexity is not None:
            task_config["complexity"] = update.complexity
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–µ
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
        orchestrator = AIModelOrchestratorService()
        orchestrator.reload_config()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–∏–ª–∏—Å—å
        updated_config = orchestrator.config.get("task_model_mapping", {}).get(update.task_type, {})
        
        return {
            "success": True,
            "message": f"–ú–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏ '{update.task_type}' –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞",
            "task_config": task_config,
            "applied_config": updated_config,
            "note": "–ò–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –æ—Ç–∫–ª—é—á–µ–Ω–∞ - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /api/models/load –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π Ollama."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {str(e)}")


@router.put("/config/bulk", response_model=BulkModelUpdateResponse)
async def bulk_update_models(
    request: BulkModelUpdateRequest,
    db: Session = Depends(get_db),
    _: object = Depends(require_admin)
):
    """
    –ú–∞—Å—Å–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞—á
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_paths = [
            "backend/ai_model_config.json",
            "ai_model_config.json",
            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "ai_model_config.json")
        ]
        
        config_path = None
        for path in config_paths:
            if os.path.exists(path):
                config_path = path
                break
        
        if not config_path:
            config_path = config_paths[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –ø—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)
        else:
            config = {"task_model_mapping": {}}
        
        if "task_model_mapping" not in config:
            config["task_model_mapping"] = {}
        
        updated_tasks = []
        errors = []
        
        for update in request.updates:
            try:
                if update.task_type not in config["task_model_mapping"]:
                    config["task_model_mapping"][update.task_type] = {
                        "primary": "",
                        "fallback": "",
                        "complexity": "light"
                    }
                
                task_config = config["task_model_mapping"][update.task_type]
                
                if update.primary is not None:
                    task_config["primary"] = update.primary
                if update.fallback is not None:
                    task_config["fallback"] = update.fallback
                if update.complexity is not None:
                    task_config["complexity"] = update.complexity
                
                updated_tasks.append(update.task_type)
            except Exception as e:
                errors.append(f"{update.task_type}: {str(e)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–µ
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
        orchestrator = AIModelOrchestratorService()
        orchestrator.reload_config()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–∏–ª–∏—Å—å
        applied_configs = {}
        for task in updated_tasks:
            applied_configs[task] = orchestrator.config.get("task_model_mapping", {}).get(task, {})
        
        return BulkModelUpdateResponse(
            success=len(errors) == 0,
            updated_tasks=updated_tasks,
            errors=errors
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –º–∞—Å—Å–æ–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {str(e)}")


@router.put("/settings", response_model=Dict[str, Any])
async def update_ai_settings(
    settings: AIModelSettings,
    db: Session = Depends(get_db),
    _: object = Depends(require_admin)
):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
        settings_paths = [
            "backend/ai_settings.json",
            "ai_settings.json",
            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "ai_settings.json")
        ]
        
        settings_path = None
        for path in settings_paths:
            if os.path.exists(path):
                settings_path = path
                break
        
        if not settings_path:
            settings_path = settings_paths[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –ø—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        current_settings = {}
        if os.path.exists(settings_path):
            with open(settings_path, "r", encoding="utf-8") as f:
                current_settings = json.load(f)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        current_settings["response_model"] = settings.response_model
        current_settings["embedding_model"] = settings.embedding_model
        if settings.api_service:
            current_settings["api_service"] = settings.api_service
        if settings.api_key:
            current_settings["api_key"] = settings.api_key
        if settings.deep_thinking_model:
            current_settings["deep_thinking_model"] = settings.deep_thinking_model
        if settings.deepseek_api_key:
            current_settings["deepseek_api_key"] = settings.deepseek_api_key
        
        current_settings["updated_at"] = datetime.utcnow().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        with open(settings_path, "w", encoding="utf-8") as f:
            json.dump(current_settings, f, indent=2, ensure_ascii=False)
        
        return {
            "success": True,
            "message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ AI –æ–±–Ω–æ–≤–ª–µ–Ω—ã",
            "settings": current_settings
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫: {str(e)}")


@router.post("/test", response_model=ModelTestResponse)
async def test_model(
    request: ModelTestRequest,
    db: Session = Depends(get_db),
    _: object = Depends(require_admin)
):
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å –∑–∞–¥–∞–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
    """
    try:
        import time
        
        test_prompt = request.test_prompt or "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."
        
        start_time = time.time()
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
            # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
            original_settings = _load_ai_settings()
            temp_settings = original_settings.copy()
            temp_settings["response_model"] = request.model_name
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
            settings_paths = [
                "backend/ai_settings.json",
                "ai_settings.json",
                os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "ai_settings.json")
            ]
            
            settings_path = None
            for path in settings_paths:
                if os.path.exists(path):
                    settings_path = path
                    break
            
            if not settings_path:
                settings_path = settings_paths[0]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –ø—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            with open(settings_path, "w", encoding="utf-8") as f:
                json.dump(temp_settings, f, indent=2, ensure_ascii=False)
            
            try:
                response, model_info = await _generate_with_ai_settings(
                    prompt=test_prompt,
                    deep_thinking_enabled=False
                )
                
                response_time = time.time() - start_time
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                with open(settings_path, "w", encoding="utf-8") as f:
                    json.dump(original_settings, f, indent=2, ensure_ascii=False)
                
                return ModelTestResponse(
                    success=True,
                    response=response,
                    response_time=response_time,
                    model_info=model_info
                )
            except Exception as e:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                with open(settings_path, "w", encoding="utf-8") as f:
                    json.dump(original_settings, f, indent=2, ensure_ascii=False)
                raise e
                
        except Exception as e:
            response_time = time.time() - start_time
            return ModelTestResponse(
                success=False,
                response_time=response_time,
                error=str(e)
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {str(e)}")


@router.get("/performance", response_model=List[ModelPerformanceMetrics])
async def get_model_performance(
    model_name: Optional[str] = None,
    task_type: Optional[str] = None,
    db: Session = Depends(get_db),
    _: object = Depends(require_admin)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
    """
    try:
        orchestrator = AIModelOrchestratorService()
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = orchestrator.get_model_performance(
            model_name=model_name,
            task_type=TaskType(task_type) if task_type else None
        )
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
        result = []
        for model, data in metrics.items():
            result.append(ModelPerformanceMetrics(
                model_name=model,
                task_type=data.get("task_type"),
                success_rate=data.get("success_rate"),
                avg_response_time=data.get("avg_response_time"),
                total_requests=data.get("total_requests"),
                last_used=data.get("last_used")
            ))
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {str(e)}")


@router.get("/available")
async def get_available_models(
    db: Session = Depends(get_db)
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    """
    try:
        orchestrator = AIModelOrchestratorService()
        available_models = await orchestrator.get_available_models()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º
        grouped = {
            "ollama": [],
            "mistral": [],
            "openai": [],
            "anthropic": [],
            "deepseek": [],
            "other": []
        }
        
        for model in available_models:
            if model.startswith("ollama:"):
                grouped["ollama"].append(model.replace("ollama:", ""))
            elif model.startswith("mistral:"):
                grouped["mistral"].append(model.replace("mistral:", ""))
            elif model.startswith("openai:"):
                grouped["openai"].append(model.replace("openai:", ""))
            elif model.startswith("anthropic:"):
                grouped["anthropic"].append(model.replace("anthropic:", ""))
            elif model.startswith("deepseek:"):
                grouped["deepseek"].append(model.replace("deepseek:", ""))
            else:
                grouped["other"].append(model)
        
        return {
            "all_models": available_models,
            "grouped_by_provider": grouped,
            "total_count": len(available_models)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")


@router.post("/load", response_model=Dict[str, Any])
async def load_model_manually(
    model_name: str,
    db: Session = Depends(get_db),
    _: object = Depends(require_admin)
):
    """
    –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Ollama –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –º–æ–¥–µ–ª—å Ollama
        if not model_name.startswith("ollama:"):
            raise HTTPException(
                status_code=400,
                detail="–†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π Ollama. –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏—Ö API."
            )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏
        actual_model_name = model_name.replace("ollama:", "")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
        from services.ollama_utils import find_working_ollama_url
        working_url = await find_working_ollama_url(timeout=2.0)
        if not working_url:
            raise HTTPException(status_code=400, detail="Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω.")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ
        orchestrator = AIModelOrchestratorService()
        available_models = await orchestrator.get_available_models()
        
        if model_name in available_models:
            return {
                "success": True,
                "message": f"–ú–æ–¥–µ–ª—å {actual_model_name} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
                "model": actual_model_name,
                "status": "already_loaded"
            }
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print(f"üì• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–ø—Ä–æ—Å–∏–ª –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ {actual_model_name}")
        await orchestrator._auto_load_model(actual_model_name, working_url, timeout=300.0)
        
        return {
            "success": True,
            "message": f"–ú–æ–¥–µ–ª—å {actual_model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
            "model": actual_model_name,
            "status": "loaded"
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")


def _load_ai_settings() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI"""
    default_settings = {
        "response_model": "mistral:mistral-large-latest",
        "embedding_model": "",
        "api_service": "mistral",
        "api_key": "",
        "deep_thinking_model": "",
        "deepseek_api_key": ""
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
    settings_paths = [
        "backend/ai_settings.json",
        "ai_settings.json",
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "ai_settings.json")
    ]
    
    for settings_path in settings_paths:
        if os.path.exists(settings_path):
            try:
                with open(settings_path, "r", encoding="utf-8") as f:
                    settings = json.load(f)
                    default_settings.update(settings)
                break
            except Exception:
                continue
    
    return default_settings

